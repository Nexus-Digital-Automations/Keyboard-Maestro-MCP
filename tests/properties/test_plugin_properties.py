# tests/properties/test_plugin_properties.py
"""
Property-Based Testing Infrastructure for Plugin System.

This module implements comprehensive property-based tests using Hypothesis
to validate plugin operations under thousands of generated edge cases,
ensuring correctness, security, and reliability across all scenarios.

Target: Comprehensive property coverage with metamorphic testing
"""

import pytest
from hypothesis import given, strategies as st, assume, settings, Verbosity
from hypothesis.stateful import RuleBasedStateMachine, rule, invariant, initialize, Bundle
from typing import Dict, List, Any, Optional
from pathlib import Path
import tempfile
import json
from datetime import datetime, timedelta
import uuid

from src.types.plugin_types import (
    PluginID, PluginName, create_plugin_id, create_plugin_name, create_script_content,
    create_security_hash, create_risk_score, MAX_PLUGIN_NAME_LENGTH, DEFAULT_TIMEOUT_SECONDS
)
from src.types.domain_types import PluginCreationData, PluginMetadata, PluginParameter
from src.types.enumerations import PluginScriptType, PluginSecurityLevel, PluginLifecycleState, PluginOutputHandling
from src.types.results import Result
from src.core.plugin_core import (
    create_plugin_metadata, generate_info_plist_content, create_plugin_bundle,
    validate_plugin_bundle, create_installation_plan, DEFAULT_PLUGIN_CORE
)
from src.boundaries.plugin_boundaries import validate_plugin_security
from src.tools.plugin_management import (
    km_create_plugin_action, km_install_plugin, km_list_custom_plugins,
    km_validate_plugin, km_remove_plugin, clear_plugin_registry, get_plugin_registry
)


# Hypothesis Strategies for Plugin Domain

@st.composite
def valid_plugin_names(draw):
    """Generate valid plugin names."""
    # Valid characters for plugin names
    name_length = draw(st.integers(min_value=1, max_value=MAX_PLUGIN_NAME_LENGTH))
    # Use alphanumeric, spaces, underscores, hyphens, and dots
    chars = st.characters(
        whitelist_categories=('Lu', 'Ll', 'Nd'),  # Letters and digits
        whitelist_characters=' _-.'
    )
    name = draw(st.text(alphabet=chars, min_size=name_length, max_size=name_length))
    assume(name.strip())  # Ensure not just whitespace
    return name.strip()


@st.composite  
def plugin_script_content(draw, script_type=None):
    """Generate valid script content for different types."""
    if script_type is None:
        script_type = draw(st.sampled_from(list(PluginScriptType)))
    
    # Base script templates for each type
    templates = {
        PluginScriptType.APPLESCRIPT: [
            'tell application "System Events" to display notification "Hello"',
            'set theValue to text returned of (display dialog "Enter value:")\nreturn theValue',
            'tell application "Finder" to get name of front window'
        ],
        PluginScriptType.SHELL: [
            'echo "Hello World"',
            'date +"%Y-%m-%d %H:%M:%S"',
            'whoami'
        ],
        PluginScriptType.PYTHON: [
            'print("Hello World")',
            'import datetime\nprint(datetime.datetime.now())',
            'result = input("Enter value: ")\nprint(f"You entered: {result}")'
        ],
        PluginScriptType.JAVASCRIPT: [
            'console.log("Hello World");',
            'const date = new Date();\nconsole.log(date.toISOString());',
            'const value = prompt("Enter value:");\nconsole.log(`You entered: ${value}`);'
        ],
        PluginScriptType.PHP: [
            '<?php echo "Hello World"; ?>',
            '<?php echo date("Y-m-d H:i:s"); ?>',
            '<?php $value = readline("Enter value: "); echo "You entered: " . $value; ?>'
        ]
    }
    
    base_script = draw(st.sampled_from(templates[script_type]))
    
    # Optionally add safe variations
    variations = draw(st.lists(st.sampled_from([
        '\n// Generated by MCP Plugin System',
        '\n# Safe script variation',
        '\n-- Comment line'
    ]), max_size=3))
    
    return base_script + ''.join(variations)


@st.composite
def safe_script_content(draw):
    """Generate guaranteed safe script content."""
    script_type = draw(st.sampled_from(list(PluginScriptType)))
    content = draw(plugin_script_content(script_type))
    
    # Ensure no dangerous patterns
    dangerous_patterns = ['rm -rf', 'sudo', 'eval(', 'exec(', 'system(']
    assume(not any(pattern in content.lower() for pattern in dangerous_patterns))
    
    return content, script_type


@st.composite
def plugin_parameters(draw):
    """Generate valid plugin parameters."""
    param_count = draw(st.integers(min_value=0, max_value=10))
    params = []
    
    for i in range(param_count):
        param = PluginParameter(
            name=f"KMPARAM_Param{i+1}",
            label=draw(st.text(min_size=1, max_size=50, alphabet=st.characters(
                whitelist_categories=('Lu', 'Ll', 'Nd'), whitelist_characters=' _-'
            ))),
            parameter_type=draw(st.sampled_from(['string', 'number', 'boolean', 'choice'])),
            default_value=draw(st.one_of(st.none(), st.text(max_size=100)))
        )
        params.append(param)
    
    return params


@st.composite
def plugin_creation_data(draw):
    """Generate valid PluginCreationData instances."""
    action_name = draw(valid_plugin_names())
    script_content, script_type = draw(safe_script_content())
    
    return PluginCreationData(
        action_name=action_name,
        script_content=script_content,
        script_type=script_type,
        description=draw(st.one_of(st.none(), st.text(max_size=500))),
        parameters=draw(plugin_parameters()),
        output_handling=draw(st.one_of(st.none(), st.sampled_from(list(PluginOutputHandling)))),
        security_level=draw(st.sampled_from(list(PluginSecurityLevel)))
    )


# Property-Based Tests for Plugin Creation

@given(creation_data=plugin_creation_data())
@settings(max_examples=100, verbosity=Verbosity.verbose)
def test_plugin_creation_properties(creation_data):
    """Test fundamental properties of plugin creation."""
    
    # Property 1: Valid input always produces metadata
    metadata_result = create_plugin_metadata(creation_data)
    assert metadata_result.is_success, f"Valid input should produce metadata: {metadata_result._error}"
    
    metadata = metadata_result.unwrap()
    
    # Property 2: Metadata preserves input properties
    assert metadata.action_name == creation_data.action_name
    assert metadata.script_type == creation_data.script_type
    assert metadata.description == creation_data.description
    assert len(metadata.parameters) == len(creation_data.parameters or [])
    
    # Property 3: Plugin ID is unique and well-formed
    assert isinstance(metadata.plugin_id, str)
    assert metadata.plugin_id.startswith("mcp_plugin_")
    assert len(metadata.plugin_id) > len("mcp_plugin_")
    
    # Property 4: Content hash is consistent
    hash1 = create_security_hash(creation_data.script_content)
    hash2 = create_security_hash(creation_data.script_content)
    assert hash1 == hash2, "Content hash should be deterministic"
    assert metadata.content_hash == hash1, "Metadata should store correct content hash"
    
    # Property 5: Risk score is within valid range
    assert 0 <= metadata.risk_score <= 100, f"Risk score out of range: {metadata.risk_score}"
    
    # Property 6: Creation timestamp is recent
    time_diff = datetime.now() - metadata.created_at
    assert time_diff.total_seconds() < 10, "Creation timestamp should be recent"
    
    # Property 7: Initial state is CREATED
    assert metadata.state == PluginLifecycleState.CREATED


@given(creation_data=plugin_creation_data())
def test_plugin_creation_idempotency(creation_data):
    """Test that plugin creation with same input produces equivalent results."""
    
    # Create metadata twice with same input
    result1 = create_plugin_metadata(creation_data)
    result2 = create_plugin_metadata(creation_data)
    
    assert result1.is_success and result2.is_success
    
    metadata1 = result1.unwrap()
    metadata2 = result2.unwrap()
    
    # Properties that should be identical
    assert metadata1.action_name == metadata2.action_name
    assert metadata1.script_type == metadata2.script_type
    assert metadata1.content_hash == metadata2.content_hash
    assert metadata1.risk_score == metadata2.risk_score
    
    # Properties that should be different (unique identifiers and timestamps)
    assert metadata1.plugin_id != metadata2.plugin_id, "Plugin IDs should be unique"


@given(creation_data=plugin_creation_data())
def test_info_plist_generation_properties(creation_data):
    """Test properties of Info.plist generation."""
    
    # Create metadata first
    metadata_result = create_plugin_metadata(creation_data)
    assume(metadata_result.is_success)
    metadata = metadata_result.unwrap()
    
    # Generate Info.plist
    plist_result = generate_info_plist_content(metadata, creation_data)
    assert plist_result.is_success, f"Info.plist generation failed: {plist_result._error}"
    
    plist_content = plist_result.unwrap()
    
    # Property 1: Result is valid XML
    try:
        import xml.etree.ElementTree as ET
        root = ET.fromstring(plist_content)
        assert root.tag == "plist"
    except ET.ParseError:
        pytest.fail("Generated Info.plist is not valid XML")
    
    # Property 2: Contains required keys
    plist_str = plist_content.decode('utf-8')
    required_keys = ["CFBundleIdentifier", "CFBundleDisplayName", "KMScriptType"]
    for key in required_keys:
        assert key in plist_str, f"Missing required key: {key}"
    
    # Property 3: Script type is preserved
    assert creation_data.script_type.value in plist_str
    
    # Property 4: Action name is preserved
    assert creation_data.action_name in plist_str


# Property-Based Tests for Plugin Bundle Operations

@given(creation_data=plugin_creation_data())
def test_plugin_bundle_creation_properties(creation_data):
    """Test properties of plugin bundle creation."""
    
    with tempfile.TemporaryDirectory() as temp_dir:
        # Create metadata
        metadata_result = create_plugin_metadata(creation_data)
        assume(metadata_result.is_success)
        metadata = metadata_result.unwrap()
        
        # Create bundle
        bundle_result = create_plugin_bundle(metadata, creation_data, temp_dir)
        assert bundle_result.is_success, f"Bundle creation failed: {bundle_result._error}"
        
        bundle = bundle_result.unwrap()
        
        # Property 1: Bundle contains all required components
        assert bundle.plugin_id == metadata.plugin_id
        assert bundle.name == metadata.name
        assert len(bundle.info_plist) > 0
        assert len(bundle.script_files) > 0
        
        # Property 2: Script files contain original content
        script_found = False
        for filename, content in bundle.script_files:
            if creation_data.script_content.encode('utf-8') in content:
                script_found = True
                break
        assert script_found, "Original script content not found in bundle"
        
        # Property 3: Bundle path is well-formed
        assert str(bundle.bundle_path).endswith('.kmsync')
        assert creation_data.action_name.replace(' ', '_') in str(bundle.bundle_path)
        
        # Property 4: Security context is properly initialized
        assert bundle.security_context.plugin_id == metadata.plugin_id
        assert bundle.security_context.security_level == metadata.security_level
        assert bundle.security_context.risk_score == metadata.risk_score


@given(creation_data=plugin_creation_data())
def test_plugin_validation_properties(creation_data):
    """Test properties of plugin validation."""
    
    with tempfile.TemporaryDirectory() as temp_dir:
        # Create complete bundle
        metadata_result = create_plugin_metadata(creation_data)
        assume(metadata_result.is_success)
        metadata = metadata_result.unwrap()
        
        bundle_result = create_plugin_bundle(metadata, creation_data, temp_dir)
        assume(bundle_result.is_success)
        bundle = bundle_result.unwrap()
        
        # Validate bundle
        validation_result = validate_plugin_bundle(bundle)
        assert validation_result.is_success, f"Validation failed: {validation_result._error}"
        
        validation = validation_result.unwrap()
        
        # Property 1: Validation result is consistent
        if validation.is_valid:
            assert not validation.validation_errors or len(validation.validation_errors) == 0
        else:
            assert validation.validation_errors and len(validation.validation_errors) > 0
        
        # Property 2: Risk level is reasonable
        assert 0 <= validation.estimated_risk_level <= 3
        
        # Property 3: Security issues are properly categorized
        if validation.security_issues:
            for issue in validation.security_issues:
                assert isinstance(issue, str)
                assert len(issue) > 0


# Metamorphic Testing Properties

@given(creation_data=plugin_creation_data())
def test_plugin_creation_round_trip_property(creation_data):
    """Test round-trip property: create → serialize → deserialize → recreate."""
    
    # Create original metadata
    original_result = create_plugin_metadata(creation_data)
    assume(original_result.is_success)
    original = original_result.unwrap()
    
    # Simulate serialization/deserialization cycle
    serialized = {
        'action_name': original.action_name,
        'script_type': original.script_type.value,
        'script_content': creation_data.script_content,
        'description': original.description,
        'security_level': original.security_level.value
    }
    
    # Recreate from serialized data
    reconstructed_data = PluginCreationData(
        action_name=serialized['action_name'],
        script_content=serialized['script_content'],
        script_type=PluginScriptType(serialized['script_type']),
        description=serialized['description'],
        security_level=PluginSecurityLevel(serialized['security_level'])
    )
    
    reconstructed_result = create_plugin_metadata(reconstructed_data)
    assert reconstructed_result.is_success
    reconstructed = reconstructed_result.unwrap()
    
    # Round-trip properties that should be preserved
    assert original.action_name == reconstructed.action_name
    assert original.script_type == reconstructed.script_type
    assert original.content_hash == reconstructed.content_hash
    assert original.security_level == reconstructed.security_level


@given(creation_data=plugin_creation_data())
def test_plugin_validation_consistency_property(creation_data):
    """Test that validation is consistent across multiple calls."""
    
    # Create plugin and validate multiple times
    security_results = []
    for _ in range(3):
        security_result = validate_plugin_security(creation_data)
        security_results.append(security_result)
    
    # All results should be identical
    first_result = security_results[0]
    for result in security_results[1:]:
        assert result.is_valid == first_result.is_valid
        assert result.estimated_risk_level == first_result.estimated_risk_level
        assert set(result.security_issues or []) == set(first_result.security_issues or [])


# Property-Based Tests for Plugin Tools

@given(action_name=valid_plugin_names(), script_content=st.text(min_size=10, max_size=1000))
@settings(max_examples=50)
async def test_plugin_tool_creation_properties(action_name, script_content):
    """Test properties of plugin tool operations."""
    
    # Ensure clean state
    clear_plugin_registry()
    
    # Filter out dangerous content
    dangerous_patterns = ['rm -rf', 'sudo', 'eval(', 'exec(']
    assume(not any(pattern in script_content.lower() for pattern in dangerous_patterns))
    
    # Test plugin creation tool
    result = await km_create_plugin_action(
        action_name=action_name,
        script_content=script_content,
        script_type="applescript"
    )
    
    # Property 1: Valid input produces success or specific error
    assert 'success' in result
    assert isinstance(result['success'], bool)
    
    if result['success']:
        # Property 2: Successful creation returns plugin details
        assert 'plugin_id' in result
        assert 'plugin_name' in result
        assert 'bundle_path' in result
        assert 'content_hash' in result
        
        # Property 3: Plugin ID is well-formed
        assert result['plugin_id'].startswith('mcp_plugin_')
        
        # Property 4: Plugin appears in registry
        registry = get_plugin_registry()
        assert result['plugin_id'] in registry
        
        # Property 5: Registry entry matches creation data
        metadata = registry[result['plugin_id']]
        assert metadata.action_name == action_name
        assert metadata.script_type == PluginScriptType.APPLESCRIPT
    else:
        # Property 6: Failed creation provides error details
        assert 'error' in result
        assert 'message' in result['error']
        assert 'recovery_suggestion' in result['error']


# Stateful Testing with Hypothesis

class PluginSystemStateMachine(RuleBasedStateMachine):
    """Stateful testing of plugin system operations."""
    
    def __init__(self):
        super().__init__()
        self.plugins = {}
        self.installed_plugins = set()
        
    @initialize()
    def setup(self):
        """Initialize clean state."""
        clear_plugin_registry()
        self.plugins.clear()
        self.installed_plugins.clear()
    
    plugins_bundle = Bundle('plugins')
    
    @rule(target=plugins_bundle, 
          action_name=valid_plugin_names(),
          script_content=st.text(min_size=10, max_size=500))
    async def create_plugin(self, action_name, script_content):
        """Rule: Create a new plugin."""
        
        # Filter dangerous content
        dangerous_patterns = ['rm -rf', 'sudo', 'eval(']
        assume(not any(pattern in script_content.lower() for pattern in dangerous_patterns))
        
        result = await km_create_plugin_action(
            action_name=action_name,
            script_content=script_content,
            script_type="applescript"
        )
        
        if result['success']:
            plugin_id = result['plugin_id']
            self.plugins[plugin_id] = {
                'action_name': action_name,
                'script_content': script_content,
                'created_at': datetime.now()
            }
            return plugin_id
        else:
            return None
    
    @rule(plugin_id=plugins_bundle)
    async def install_plugin(self, plugin_id):
        """Rule: Install an existing plugin."""
        assume(plugin_id is not None)
        assume(plugin_id not in self.installed_plugins)
        
        with tempfile.TemporaryDirectory() as temp_dir:
            result = await km_install_plugin(
                plugin_id=plugin_id,
                target_directory=temp_dir
            )
            
            if result['success']:
                self.installed_plugins.add(plugin_id)
    
    @rule(plugin_id=plugins_bundle)
    async def validate_plugin(self, plugin_id):
        """Rule: Validate an existing plugin."""
        assume(plugin_id is not None)
        
        result = await km_validate_plugin(plugin_id)
        
        # Validation should always return structured results
        assert 'success' in result
        if result['success']:
            assert 'validation_results' in result
            assert 'overall_status' in result['validation_results']
    
    @rule(plugin_id=plugins_bundle)
    async def remove_plugin(self, plugin_id):
        """Rule: Remove an existing plugin."""
        assume(plugin_id is not None)
        
        result = await km_remove_plugin(plugin_id)
        
        if result['success']:
            self.plugins.pop(plugin_id, None)
            self.installed_plugins.discard(plugin_id)
    
    @rule()
    async def list_plugins(self):
        """Rule: List all plugins."""
        result = await km_list_custom_plugins()
        
        # Listing should always succeed
        assert result['success']
        assert 'plugins' in result
        assert 'summary' in result
        
        # Summary should match actual plugin count
        plugin_count = len(result['plugins'])
        assert result['summary']['total_plugins'] == plugin_count
    
    @invariant()
    def registry_consistency(self):
        """Invariant: Registry state is consistent with tracked state."""
        registry = get_plugin_registry()
        
        # All tracked plugins should be in registry
        for plugin_id in self.plugins:
            if plugin_id in registry:
                metadata = registry[plugin_id]
                tracked = self.plugins[plugin_id]
                assert metadata.action_name == tracked['action_name']
    
    @invariant()
    def plugin_id_uniqueness(self):
        """Invariant: All plugin IDs are unique."""
        registry = get_plugin_registry()
        plugin_ids = list(registry.keys())
        assert len(plugin_ids) == len(set(plugin_ids))
    
    @invariant()
    def installed_plugins_subset(self):
        """Invariant: Installed plugins are subset of created plugins."""
        registry = get_plugin_registry()
        for plugin_id in self.installed_plugins:
            assert plugin_id in registry


# Test the stateful machine
PluginSystemTest = PluginSystemStateMachine.TestCase


# Security Property Tests

@given(script_content=st.text(min_size=1, max_size=1000))
def test_security_boundary_properties(script_content):
    """Test security boundary enforcement properties."""
    
    # Create test data
    test_data = PluginCreationData(
        action_name="Security Test",
        script_content=script_content,
        script_type=PluginScriptType.SHELL,
        security_level=PluginSecurityLevel.SANDBOXED
    )
    
    # Validate security
    security_result = validate_plugin_security(test_data)
    
    # Property 1: Security validation always returns structured result
    assert hasattr(security_result, 'is_valid')
    assert hasattr(security_result, 'security_issues')
    assert hasattr(security_result, 'warnings')
    assert hasattr(security_result, 'estimated_risk_level')
    
    # Property 2: Risk level is within bounds
    assert 0 <= security_result.estimated_risk_level <= 3
    
    # Property 3: Dangerous patterns are detected
    dangerous_patterns = ['rm -rf /', 'sudo rm', 'eval(', 'exec(']
    has_dangerous = any(pattern in script_content.lower() for pattern in dangerous_patterns)
    
    if has_dangerous:
        assert not security_result.is_valid or security_result.security_issues
    
    # Property 4: Security issues are descriptive
    if security_result.security_issues:
        for issue in security_result.security_issues:
            assert isinstance(issue, str)
            assert len(issue) > 10  # Meaningful description


# Performance Property Tests

@given(plugin_count=st.integers(min_value=1, max_value=20))
@settings(max_examples=10)
async def test_plugin_system_performance_properties(plugin_count):
    """Test performance properties of plugin system operations."""
    
    clear_plugin_registry()
    
    # Create multiple plugins and measure performance
    start_time = datetime.now()
    
    created_plugins = []
    for i in range(plugin_count):
        result = await km_create_plugin_action(
            action_name=f"Performance Test Plugin {i}",
            script_content=f'echo "Plugin {i}"',
            script_type="shell"
        )
        
        if result['success']:
            created_plugins.append(result['plugin_id'])
    
    creation_time = (datetime.now() - start_time).total_seconds()
    
    # Property 1: Creation time scales reasonably
    assert creation_time < plugin_count * 2.0  # Max 2 seconds per plugin
    
    # List plugins and measure performance
    start_time = datetime.now()
    list_result = await km_list_custom_plugins()
    list_time = (datetime.now() - start_time).total_seconds()
    
    # Property 2: Listing is fast regardless of plugin count
    assert list_time < 1.0  # Max 1 second to list
    assert list_result['success']
    
    # Property 3: Listed count matches created count
    assert list_result['summary']['total_plugins'] == len(created_plugins)


# Edge Case Property Tests

@given(
    action_name=st.one_of(
        st.text(min_size=1, max_size=1),  # Minimal names
        st.text(min_size=MAX_PLUGIN_NAME_LENGTH, max_size=MAX_PLUGIN_NAME_LENGTH),  # Maximum names
        st.text(alphabet=st.characters(whitelist_categories=('Zs',)), min_size=1, max_size=10)  # Whitespace
    )
)
def test_plugin_name_edge_cases(action_name):
    """Test plugin name handling for edge cases."""
    
    try:
        plugin_name = create_plugin_name(action_name)
        
        # Property 1: Valid names are preserved
        assert len(plugin_name) <= MAX_PLUGIN_NAME_LENGTH
        assert plugin_name.strip() == plugin_name  # No leading/trailing whitespace
        
    except ValueError:
        # Property 2: Invalid names are rejected
        assert (
            len(action_name.strip()) == 0 or  # Empty after strip
            len(action_name) > MAX_PLUGIN_NAME_LENGTH or  # Too long
            not action_name.strip()  # Just whitespace
        )


@given(
    script_content=st.one_of(
        st.text(min_size=0, max_size=0),  # Empty content
        st.text(min_size=1000000, max_size=1000001),  # Too large
        st.text(alphabet=st.characters(blacklist_categories=('Cc',)), min_size=1, max_size=100)  # Control chars
    )
)
def test_script_content_edge_cases(script_content):
    """Test script content validation for edge cases."""
    
    try:
        validated_content = create_script_content(script_content, PluginScriptType.APPLESCRIPT)
        
        # Property 1: Valid content is preserved
        assert len(validated_content) <= 1_000_000
        assert len(validated_content.strip()) > 0
        
    except ValueError:
        # Property 2: Invalid content is rejected
        assert (
            len(script_content.strip()) == 0 or  # Empty
            len(script_content) > 1_000_000  # Too large
        )


# Test Configuration

pytestmark = pytest.mark.asyncio

# Configure Hypothesis for comprehensive testing
settings.register_profile("comprehensive", 
                         max_examples=200, 
                         verbosity=Verbosity.verbose,
                         deadline=None)

settings.register_profile("quick",
                         max_examples=20,
                         verbosity=Verbosity.normal)

# Export test functions for pytest discovery
__all__ = [
    "test_plugin_creation_properties",
    "test_plugin_creation_idempotency", 
    "test_info_plist_generation_properties",
    "test_plugin_bundle_creation_properties",
    "test_plugin_validation_properties",
    "test_plugin_creation_round_trip_property",
    "test_plugin_validation_consistency_property",
    "test_plugin_tool_creation_properties",
    "PluginSystemTest",
    "test_security_boundary_properties",
    "test_plugin_system_performance_properties",
    "test_plugin_name_edge_cases",
    "test_script_content_edge_cases"
]
